{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First page's url is here: https://www.newegg.com/Product/ProductList.aspx?Submit=Property&N=100019096%2050010772%2050001186%2050010418%208000&IsNodeId=1&bop=And&Order=RELEASE&PageSize=96\n",
    "\n",
    "**Sorting parameters within this page:**\n",
    "* Seller is Newegg\n",
    "* Brand is Dell, HP, Lenovo\n",
    "* Sort by Newest to Oldest\n",
    "* 96 Products per page\n",
    "* Date is 10/3 at 10:33 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    r = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(r.text, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_components(html):\n",
    "    '''Grabs all available PC components from Newegg webpage. \n",
    "       ====Parameters====\n",
    "       soup: BeautifulSoup object (use get_soup() function)\n",
    "       ====Returns====\n",
    "       this_computer: OrderedDict mapping this computer's variables to values\n",
    "    '''\n",
    "    soup = bs4.BeautifulSoup(html, 'lxml')\n",
    "    # Narrow down to specifications part of page\n",
    "    specs = soup.find('div', class_='plinks')\n",
    "    # All categories of technical specifications in dt tags\n",
    "    categories = specs.find_all('dt')\n",
    "    # All details of technical specifications in dd tags\n",
    "    details = specs.find_all('dd')\n",
    "    \n",
    "    this_computer = OrderedDict()\n",
    "    \n",
    "    for cat, det in zip(categories, details):\n",
    "        # raw detail is always located here\n",
    "        raw_det = det.contents[0]\n",
    "        \n",
    "        # in some cases, have to go one tag deeper to get category name\n",
    "        if type(cat.contents[0]) == bs4.element.Tag:\n",
    "            raw_cat = cat.contents[0].contents[0]\n",
    "        else:\n",
    "            raw_cat = cat.contents[0]\n",
    "            \n",
    "        this_computer[raw_cat] = raw_det\n",
    "    return this_computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processor_brand(processor):\n",
    "    # Return the first word in the processor description (usually the brand)\n",
    "    return processor.split(' ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ram_cap(memory):\n",
    "    # Returns RAM capacity\n",
    "    return memory.upper().split('GB')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ram_type(memory):\n",
    "    # Returns type of RAM (DDR2, DDR3, or DDR4)\n",
    "    memory = memory.upper()\n",
    "    if 'DDR2' in memory:\n",
    "        return 'ddr2'\n",
    "    if 'DDR3' in memory:\n",
    "        return 'ddr3'\n",
    "    # DDR4 is industry standard these days, we default to it\n",
    "    else:\n",
    "        return 'ddr4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disk_cap(storage):\n",
    "    # Returns the disk capacity of a hard disk (will also grab first letter of storage unit GB or TB)\n",
    "    storage = storage.upper()\n",
    "    stor_split = storage.split('B')\n",
    "    return stor_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_or_hdd(storage):\n",
    "    # Check contents of storage for keywords indicating disk type\n",
    "    storage = storage.upper()\n",
    "    # Some systems have both SSD and HDD in \n",
    "    if ('+' in storage) or ('plus' in storage):\n",
    "        return 'both'\n",
    "    elif 'SSD' in storage:\n",
    "        return 'ssd'\n",
    "    elif 'RPM' in storage:\n",
    "        return 'hdd'\n",
    "    elif 'HDD' in storage:\n",
    "        return 'hdd'\n",
    "    else:\n",
    "        return 'hdd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-41-a73db5ef83d3>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-41-a73db5ef83d3>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    # be careful not to grab from the processor speed!\u001b[0m\n\u001b[0m                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def num_cores(processor, processor_main_features):\n",
    "    # TODO: grab number of cores based on keywords such as 'dual', 'quad', 'six', '6'. \n",
    "    # be careful not to grab from the processor speed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling with Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver = \"/usr/local/bin/chromedriver\"\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(chromedriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.newegg.com/Product/ProductList.aspx?Submit=Property&N=100019096%2050010772%2050001186%2050010418%208000&IsNodeId=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_array = driver.find_elements_by_class_name('item-container')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_html_from_one_page(driver, product_num, product_array):\n",
    "    '''Navigates from product main page in to product and returns raw html\n",
    "       driver: Selenium chrome driver\n",
    "       product_num: int 0-95 representing a product within the product array on a page\n",
    "    '''\n",
    "    product_array[product_num].click()\n",
    "    html = driver.page_source\n",
    "    driver.back()\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General scraping function\n",
    "\n",
    "We're just going to get the HTML for the product array page, and the html for each computer's page on that product array. We'll parse this data using BeautifulSoup later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def lets_scrape(url):\n",
    "    '''\n",
    "    Grabs the HTML of the product array page and the 96 computers on that page.\n",
    "    =====Parameters=====\n",
    "    Driver: Selenium Chrome driver to control Chrome browser\n",
    "    =====Returns=====\n",
    "    pandas DataFrame of two columns: price and html of page for computer of that price\n",
    "    '''\n",
    "    price_df = pd.DataFrame(columns=['array_html'])\n",
    "    \n",
    "    \n",
    "    # Instantiate Chrome window controlled by driver\n",
    "    chromedriver = \"/usr/local/bin/chromedriver\"\n",
    "    os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    \n",
    "    # Open the product page\n",
    "    driver.get(url)\n",
    "    \n",
    "    # All computer links in this \"array\"\n",
    "    product_array = driver.find_elements_by_class_name('item-container')\n",
    "    array_html = driver.page_source\n",
    "    \n",
    "    # TODO: time.sleep() with random? For how long?\n",
    "    # Loop over product_array and grab html from each product using get_html_from_one_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blacklisting measures\n",
    "* Set user agent to common browser rather than default\n",
    "* Sleep for 5-10 seconds between requests\n",
    "* Grab proxies and rotate between them if necessary\n",
    "* Access products in random order when downloading their HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_urls = [f'https://www.newegg.com/Product/ProductList.aspx?Submit=Property&N=100019096%2050010772%2050001186%2050010418%208000&IsNodeId=1&page={i}&bop=And&PageSize=96&order=RELEASE'\n",
    "              for i in range(1, 54)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_html(url):\n",
    "    r = requests.get(url)# proxies={'http': next(proxy_pool), 'https': next(proxy_pool)})\n",
    "    soup = bs4.BeautifulSoup(r.text)\n",
    "    \n",
    "    if soup.find('h2').contents[0] == \"That's not you, right?\":\n",
    "        raise ValueError('Captcha\\'d')\n",
    "    \n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices(html):\n",
    "    # Grabs all 96 prices from the product array page\n",
    "    soup = bs4.BeautifulSoup(html, 'lxml')\n",
    "    price_list = []\n",
    "    \n",
    "    price_spans = soup.find_all('span', class_='price-current-label')\n",
    "    for span in price_spans:\n",
    "        price_list.append(span.findNextSibling().contents[0])\n",
    "    return price_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(product_array):    \n",
    "    # Returns a list of 96 product links on a product list page\n",
    "    prod_links = []\n",
    "\n",
    "    for prod in product_array:\n",
    "        prod_links.append(prod.find('a', href=True)['href'])\n",
    "        \n",
    "    return prod_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_page_scrape(url):\n",
    "    from itertools import cycle\n",
    "    '''\n",
    "       Scrapes one product array page as well as each product on that page. 96 products plus\n",
    "       one set of prices for each of these products is returned in the HTML of dataframes.\n",
    "       ====Parameters====\n",
    "       url: url of product array page to be scraped\n",
    "    '''\n",
    "    prices_df = pd.DataFrame(columns=['price_html'])\n",
    "    products_df = pd.DataFrame(columns=['component_html'])\n",
    "    \n",
    "    #proxies = ['194.61.71.236:32470', '36.37.160.224:23500', '185.91.13.32:31107', '134.236.245.63:21908']\n",
    "    #proxy_pool = cycle(proxies)\n",
    "    \n",
    "    r = requests.get(url)# proxies={'http': next(proxy_pool), 'https': next(proxy_pool)})\n",
    "    \n",
    "    array_page_html = pd.DataFrame(data = [r.text], columns=['price_html'])\n",
    "    prices_df = prices_df.append(array_page_html)\n",
    "    \n",
    "    soup = bs4.BeautifulSoup(r.text, 'lxml')\n",
    "    \n",
    "    # Grab array holding all 96 products\n",
    "    product_array = soup.find_all('div', class_='item-container')\n",
    "    # Get links for each of those products\n",
    "    prod_links = get_links(product_array)\n",
    "    \n",
    "    # Scrape the html of each of those products\n",
    "    counter = 0\n",
    "    for prod_url in prod_links:\n",
    "        counter += 1\n",
    "        print(f'About to scrape page {counter}')\n",
    "        time.sleep(3 + 2.5*random.random())\n",
    "        try:\n",
    "            html = get_product_html(prod_url)\n",
    "        except:\n",
    "            html = np.nan()\n",
    "        current_page_html = pd.DataFrame(data = [html], columns=['component_html'])\n",
    "        products_df = products_df.append(current_page_html)\n",
    "        \n",
    "    return prices_df, products_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_prices = pd.DataFrame(columns=['price_html'])\n",
    "master_components = pd.DataFrame(columns=['component_html'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all(url_list, master_prices, master_components, start_at):\n",
    "    # Scrapes all pages in url_list\n",
    "    for url in url_list[start_at:]:\n",
    "        products, prices = one_page_scrape(url)\n",
    "        \n",
    "        master_prices = master_prices.append(prices, sort=True)\n",
    "        master_components = master_components.append(products, sort=True)\n",
    "        \n",
    "        master_prices.to_csv('master_price_html.csv')\n",
    "        master_components.to_csv('master_component_html.csv')\n",
    "        \n",
    "    return master_prices, master_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to scrape page 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to scrape page 2\n",
      "About to scrape page 3\n",
      "About to scrape page 4\n",
      "About to scrape page 5\n",
      "About to scrape page 6\n",
      "About to scrape page 7\n",
      "About to scrape page 8\n",
      "About to scrape page 9\n",
      "About to scrape page 10\n",
      "About to scrape page 11\n",
      "About to scrape page 12\n",
      "About to scrape page 13\n",
      "About to scrape page 14\n",
      "About to scrape page 15\n",
      "About to scrape page 16\n",
      "About to scrape page 17\n",
      "About to scrape page 18\n",
      "About to scrape page 19\n",
      "About to scrape page 20\n",
      "About to scrape page 21\n",
      "About to scrape page 22\n",
      "About to scrape page 23\n",
      "About to scrape page 24\n",
      "About to scrape page 25\n",
      "About to scrape page 26\n",
      "About to scrape page 27\n",
      "About to scrape page 28\n",
      "About to scrape page 29\n",
      "About to scrape page 30\n",
      "About to scrape page 31\n",
      "About to scrape page 32\n",
      "About to scrape page 33\n",
      "About to scrape page 34\n",
      "About to scrape page 35\n",
      "About to scrape page 36\n",
      "About to scrape page 37\n",
      "About to scrape page 38\n",
      "About to scrape page 39\n",
      "About to scrape page 40\n",
      "About to scrape page 41\n",
      "About to scrape page 42\n",
      "About to scrape page 43\n",
      "About to scrape page 44\n",
      "About to scrape page 45\n",
      "About to scrape page 46\n",
      "About to scrape page 47\n",
      "About to scrape page 48\n",
      "About to scrape page 49\n",
      "About to scrape page 50\n",
      "About to scrape page 51\n",
      "About to scrape page 52\n",
      "About to scrape page 53\n",
      "About to scrape page 54\n",
      "About to scrape page 55\n",
      "About to scrape page 56\n",
      "About to scrape page 57\n",
      "About to scrape page 58\n",
      "About to scrape page 59\n",
      "About to scrape page 60\n",
      "About to scrape page 61\n",
      "About to scrape page 62\n",
      "About to scrape page 63\n",
      "About to scrape page 64\n",
      "About to scrape page 65\n",
      "About to scrape page 66\n",
      "About to scrape page 67\n",
      "About to scrape page 68\n",
      "About to scrape page 69\n",
      "About to scrape page 70\n",
      "About to scrape page 71\n",
      "About to scrape page 72\n",
      "About to scrape page 73\n",
      "About to scrape page 74\n",
      "About to scrape page 75\n",
      "About to scrape page 76\n",
      "About to scrape page 77\n",
      "About to scrape page 78\n",
      "About to scrape page 79\n",
      "About to scrape page 80\n",
      "About to scrape page 81\n",
      "About to scrape page 82\n",
      "About to scrape page 83\n",
      "About to scrape page 84\n",
      "About to scrape page 85\n",
      "About to scrape page 86\n",
      "About to scrape page 87\n",
      "About to scrape page 88\n",
      "About to scrape page 89\n",
      "About to scrape page 90\n",
      "About to scrape page 91\n",
      "About to scrape page 92\n",
      "About to scrape page 93\n",
      "About to scrape page 94\n",
      "About to scrape page 95\n",
      "About to scrape page 96\n",
      "About to scrape page 1\n",
      "About to scrape page 2\n",
      "About to scrape page 3\n",
      "About to scrape page 4\n",
      "About to scrape page 5\n",
      "About to scrape page 6\n",
      "About to scrape page 7\n",
      "About to scrape page 8\n",
      "About to scrape page 9\n",
      "About to scrape page 10\n",
      "About to scrape page 11\n",
      "About to scrape page 12\n",
      "About to scrape page 13\n",
      "About to scrape page 14\n",
      "About to scrape page 15\n",
      "About to scrape page 16\n",
      "About to scrape page 17\n",
      "About to scrape page 18\n",
      "About to scrape page 19\n",
      "About to scrape page 20\n",
      "About to scrape page 21\n",
      "About to scrape page 22\n",
      "About to scrape page 23\n",
      "About to scrape page 24\n",
      "About to scrape page 25\n",
      "About to scrape page 26\n",
      "About to scrape page 27\n",
      "About to scrape page 28\n",
      "About to scrape page 29\n",
      "About to scrape page 30\n",
      "About to scrape page 31\n",
      "About to scrape page 32\n",
      "About to scrape page 33\n",
      "About to scrape page 34\n",
      "About to scrape page 35\n",
      "About to scrape page 36\n",
      "About to scrape page 37\n",
      "About to scrape page 38\n",
      "About to scrape page 39\n",
      "About to scrape page 40\n",
      "About to scrape page 41\n",
      "About to scrape page 42\n",
      "About to scrape page 43\n",
      "About to scrape page 44\n",
      "About to scrape page 45\n",
      "About to scrape page 46\n",
      "About to scrape page 47\n",
      "About to scrape page 48\n",
      "About to scrape page 49\n",
      "About to scrape page 50\n",
      "About to scrape page 51\n",
      "About to scrape page 52\n",
      "About to scrape page 53\n",
      "About to scrape page 54\n",
      "About to scrape page 55\n",
      "About to scrape page 56\n",
      "About to scrape page 57\n",
      "About to scrape page 58\n",
      "About to scrape page 59\n",
      "About to scrape page 60\n",
      "About to scrape page 61\n",
      "About to scrape page 62\n",
      "About to scrape page 63\n",
      "About to scrape page 64\n",
      "About to scrape page 65\n",
      "About to scrape page 66\n",
      "About to scrape page 67\n",
      "About to scrape page 68\n",
      "About to scrape page 69\n",
      "About to scrape page 70\n",
      "About to scrape page 71\n",
      "About to scrape page 72\n",
      "About to scrape page 73\n",
      "About to scrape page 74\n",
      "About to scrape page 75\n",
      "About to scrape page 76\n",
      "About to scrape page 77\n",
      "About to scrape page 78\n",
      "About to scrape page 79\n",
      "About to scrape page 80\n",
      "About to scrape page 81\n",
      "About to scrape page 82\n",
      "About to scrape page 83\n",
      "About to scrape page 84\n",
      "About to scrape page 85\n",
      "About to scrape page 86\n",
      "About to scrape page 87\n",
      "About to scrape page 88\n",
      "About to scrape page 89\n",
      "About to scrape page 90\n",
      "About to scrape page 91\n",
      "About to scrape page 92\n",
      "About to scrape page 93\n",
      "About to scrape page 94\n",
      "About to scrape page 95\n",
      "About to scrape page 96\n",
      "About to scrape page 1\n",
      "About to scrape page 2\n",
      "About to scrape page 3\n",
      "About to scrape page 4\n",
      "About to scrape page 5\n",
      "About to scrape page 6\n",
      "About to scrape page 7\n",
      "About to scrape page 8\n",
      "About to scrape page 9\n",
      "About to scrape page 10\n",
      "About to scrape page 11\n",
      "About to scrape page 12\n",
      "About to scrape page 13\n",
      "About to scrape page 14\n",
      "About to scrape page 15\n",
      "About to scrape page 16\n",
      "About to scrape page 17\n",
      "About to scrape page 18\n",
      "About to scrape page 19\n",
      "About to scrape page 20\n",
      "About to scrape page 21\n",
      "About to scrape page 22\n",
      "About to scrape page 23\n",
      "About to scrape page 24\n",
      "About to scrape page 25\n",
      "About to scrape page 26\n",
      "About to scrape page 27\n",
      "About to scrape page 28\n",
      "About to scrape page 29\n",
      "About to scrape page 30\n",
      "About to scrape page 31\n",
      "About to scrape page 32\n",
      "About to scrape page 33\n",
      "About to scrape page 34\n",
      "About to scrape page 35\n",
      "About to scrape page 36\n",
      "About to scrape page 37\n",
      "About to scrape page 38\n",
      "About to scrape page 39\n",
      "About to scrape page 40\n",
      "About to scrape page 41\n",
      "About to scrape page 42\n",
      "About to scrape page 43\n",
      "About to scrape page 44\n",
      "About to scrape page 45\n",
      "About to scrape page 46\n",
      "About to scrape page 47\n",
      "About to scrape page 48\n",
      "About to scrape page 49\n",
      "About to scrape page 50\n",
      "About to scrape page 51\n",
      "About to scrape page 52\n",
      "About to scrape page 53\n",
      "About to scrape page 54\n",
      "About to scrape page 55\n",
      "About to scrape page 56\n",
      "About to scrape page 57\n",
      "About to scrape page 58\n",
      "About to scrape page 59\n",
      "About to scrape page 60\n",
      "About to scrape page 61\n",
      "About to scrape page 62\n",
      "About to scrape page 63\n",
      "About to scrape page 64\n",
      "About to scrape page 65\n",
      "About to scrape page 66\n",
      "About to scrape page 67\n",
      "About to scrape page 68\n",
      "About to scrape page 69\n",
      "About to scrape page 70\n",
      "About to scrape page 71\n",
      "About to scrape page 72\n",
      "About to scrape page 73\n",
      "About to scrape page 74\n",
      "About to scrape page 75\n",
      "About to scrape page 76\n",
      "About to scrape page 77\n",
      "About to scrape page 78\n",
      "About to scrape page 79\n",
      "About to scrape page 80\n",
      "About to scrape page 81\n",
      "About to scrape page 82\n",
      "About to scrape page 83\n",
      "About to scrape page 84\n",
      "About to scrape page 85\n",
      "About to scrape page 86\n",
      "About to scrape page 87\n",
      "About to scrape page 88\n",
      "About to scrape page 89\n",
      "About to scrape page 90\n",
      "About to scrape page 91\n",
      "About to scrape page 92\n",
      "About to scrape page 93\n",
      "About to scrape page 94\n",
      "About to scrape page 95\n",
      "About to scrape page 96\n",
      "About to scrape page 1\n",
      "About to scrape page 2\n",
      "About to scrape page 3\n",
      "About to scrape page 4\n",
      "About to scrape page 5\n",
      "About to scrape page 6\n",
      "About to scrape page 7\n",
      "About to scrape page 8\n",
      "About to scrape page 9\n",
      "About to scrape page 10\n",
      "About to scrape page 11\n",
      "About to scrape page 12\n",
      "About to scrape page 13\n",
      "About to scrape page 14\n",
      "About to scrape page 15\n",
      "About to scrape page 16\n",
      "About to scrape page 17\n",
      "About to scrape page 18\n",
      "About to scrape page 19\n",
      "About to scrape page 20\n",
      "About to scrape page 21\n",
      "About to scrape page 22\n",
      "About to scrape page 23\n",
      "About to scrape page 24\n",
      "About to scrape page 25\n",
      "About to scrape page 26\n",
      "About to scrape page 27\n",
      "About to scrape page 28\n",
      "About to scrape page 29\n",
      "About to scrape page 30\n",
      "About to scrape page 31\n",
      "About to scrape page 32\n",
      "About to scrape page 33\n",
      "About to scrape page 34\n",
      "About to scrape page 35\n",
      "About to scrape page 36\n",
      "About to scrape page 37\n",
      "About to scrape page 38\n",
      "About to scrape page 39\n",
      "About to scrape page 40\n",
      "About to scrape page 41\n",
      "About to scrape page 42\n",
      "About to scrape page 43\n",
      "About to scrape page 44\n",
      "About to scrape page 45\n",
      "About to scrape page 46\n",
      "About to scrape page 47\n",
      "About to scrape page 48\n",
      "About to scrape page 49\n",
      "About to scrape page 50\n",
      "About to scrape page 51\n",
      "About to scrape page 52\n",
      "About to scrape page 53\n",
      "About to scrape page 54\n",
      "About to scrape page 55\n",
      "About to scrape page 56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to scrape page 57\n",
      "About to scrape page 58\n",
      "About to scrape page 59\n",
      "About to scrape page 60\n",
      "About to scrape page 61\n",
      "About to scrape page 62\n",
      "About to scrape page 63\n",
      "About to scrape page 64\n",
      "About to scrape page 65\n",
      "About to scrape page 66\n",
      "About to scrape page 67\n",
      "About to scrape page 68\n",
      "About to scrape page 69\n",
      "About to scrape page 70\n",
      "About to scrape page 71\n",
      "About to scrape page 72\n",
      "About to scrape page 73\n",
      "About to scrape page 74\n",
      "About to scrape page 75\n",
      "About to scrape page 76\n",
      "About to scrape page 77\n",
      "About to scrape page 78\n",
      "About to scrape page 79\n",
      "About to scrape page 80\n",
      "About to scrape page 81\n",
      "About to scrape page 82\n",
      "About to scrape page 83\n",
      "About to scrape page 84\n",
      "About to scrape page 85\n",
      "About to scrape page 86\n",
      "About to scrape page 87\n",
      "About to scrape page 88\n",
      "About to scrape page 89\n",
      "About to scrape page 90\n",
      "About to scrape page 91\n",
      "About to scrape page 92\n",
      "About to scrape page 93\n",
      "About to scrape page 94\n",
      "About to scrape page 95\n",
      "About to scrape page 96\n",
      "About to scrape page 1\n",
      "About to scrape page 2\n",
      "About to scrape page 3\n",
      "About to scrape page 4\n",
      "About to scrape page 5\n",
      "About to scrape page 6\n",
      "About to scrape page 7\n",
      "About to scrape page 8\n",
      "About to scrape page 9\n",
      "About to scrape page 10\n",
      "About to scrape page 11\n",
      "About to scrape page 12\n",
      "About to scrape page 13\n",
      "About to scrape page 14\n",
      "About to scrape page 15\n",
      "About to scrape page 16\n",
      "About to scrape page 17\n",
      "About to scrape page 18\n",
      "About to scrape page 19\n",
      "About to scrape page 20\n",
      "About to scrape page 21\n",
      "About to scrape page 22\n",
      "About to scrape page 23\n",
      "About to scrape page 24\n",
      "About to scrape page 25\n",
      "About to scrape page 26\n",
      "About to scrape page 27\n",
      "About to scrape page 28\n",
      "About to scrape page 29\n",
      "About to scrape page 30\n",
      "About to scrape page 31\n",
      "About to scrape page 32\n",
      "About to scrape page 33\n",
      "About to scrape page 34\n",
      "About to scrape page 35\n",
      "About to scrape page 36\n",
      "About to scrape page 37\n",
      "About to scrape page 38\n",
      "About to scrape page 39\n",
      "About to scrape page 40\n",
      "About to scrape page 41\n",
      "About to scrape page 42\n",
      "About to scrape page 43\n",
      "About to scrape page 44\n",
      "About to scrape page 45\n",
      "About to scrape page 46\n",
      "About to scrape page 47\n",
      "About to scrape page 48\n",
      "About to scrape page 49\n",
      "About to scrape page 50\n",
      "About to scrape page 51\n",
      "About to scrape page 52\n",
      "About to scrape page 53\n",
      "About to scrape page 54\n",
      "About to scrape page 55\n",
      "About to scrape page 56\n",
      "About to scrape page 57\n",
      "About to scrape page 58\n",
      "About to scrape page 59\n",
      "About to scrape page 60\n",
      "About to scrape page 61\n",
      "About to scrape page 62\n",
      "About to scrape page 63\n",
      "About to scrape page 64\n",
      "About to scrape page 65\n",
      "About to scrape page 66\n",
      "About to scrape page 67\n",
      "About to scrape page 68\n",
      "About to scrape page 69\n",
      "About to scrape page 70\n",
      "About to scrape page 71\n",
      "About to scrape page 72\n",
      "About to scrape page 73\n",
      "About to scrape page 74\n",
      "About to scrape page 75\n",
      "About to scrape page 76\n",
      "About to scrape page 77\n",
      "About to scrape page 78\n",
      "About to scrape page 79\n",
      "About to scrape page 80\n",
      "About to scrape page 81\n",
      "About to scrape page 82\n",
      "About to scrape page 83\n",
      "About to scrape page 84\n",
      "About to scrape page 85\n",
      "About to scrape page 86\n",
      "About to scrape page 87\n",
      "About to scrape page 88\n",
      "About to scrape page 89\n",
      "About to scrape page 90\n",
      "About to scrape page 91\n",
      "About to scrape page 92\n",
      "About to scrape page 93\n",
      "About to scrape page 94\n",
      "About to scrape page 95\n",
      "About to scrape page 96\n",
      "About to scrape page 1\n",
      "About to scrape page 2\n",
      "About to scrape page 3\n",
      "About to scrape page 4\n",
      "About to scrape page 5\n",
      "About to scrape page 6\n",
      "About to scrape page 7\n",
      "About to scrape page 8\n",
      "About to scrape page 9\n",
      "About to scrape page 10\n",
      "About to scrape page 11\n",
      "About to scrape page 12\n",
      "About to scrape page 13\n",
      "About to scrape page 14\n",
      "About to scrape page 15\n",
      "About to scrape page 16\n",
      "About to scrape page 17\n",
      "About to scrape page 18\n",
      "About to scrape page 19\n",
      "About to scrape page 20\n",
      "About to scrape page 21\n",
      "About to scrape page 22\n",
      "About to scrape page 23\n",
      "About to scrape page 24\n",
      "About to scrape page 25\n",
      "About to scrape page 26\n",
      "About to scrape page 27\n",
      "About to scrape page 28\n",
      "About to scrape page 29\n",
      "About to scrape page 30\n",
      "About to scrape page 31\n",
      "About to scrape page 32\n",
      "About to scrape page 33\n",
      "About to scrape page 34\n",
      "About to scrape page 35\n",
      "About to scrape page 36\n",
      "About to scrape page 37\n",
      "About to scrape page 38\n",
      "About to scrape page 39\n",
      "About to scrape page 40\n",
      "About to scrape page 41\n",
      "About to scrape page 42\n",
      "About to scrape page 43\n",
      "About to scrape page 44\n",
      "About to scrape page 45\n",
      "About to scrape page 46\n",
      "About to scrape page 47\n",
      "About to scrape page 48\n",
      "About to scrape page 49\n",
      "About to scrape page 50\n",
      "About to scrape page 51\n",
      "About to scrape page 52\n",
      "About to scrape page 53\n",
      "About to scrape page 54\n",
      "About to scrape page 55\n",
      "About to scrape page 56\n",
      "About to scrape page 57\n",
      "About to scrape page 58\n",
      "About to scrape page 59\n",
      "About to scrape page 60\n",
      "About to scrape page 61\n",
      "About to scrape page 62\n",
      "About to scrape page 63\n",
      "About to scrape page 64\n",
      "About to scrape page 65\n",
      "About to scrape page 66\n",
      "About to scrape page 67\n",
      "About to scrape page 68\n",
      "About to scrape page 69\n",
      "About to scrape page 70\n",
      "About to scrape page 71\n",
      "About to scrape page 72\n",
      "About to scrape page 73\n",
      "About to scrape page 74\n",
      "About to scrape page 75\n",
      "About to scrape page 76\n",
      "About to scrape page 77\n",
      "About to scrape page 78\n",
      "About to scrape page 79\n",
      "About to scrape page 80\n",
      "About to scrape page 81\n",
      "About to scrape page 82\n",
      "About to scrape page 83\n",
      "About to scrape page 84\n",
      "About to scrape page 85\n",
      "About to scrape page 86\n",
      "About to scrape page 87\n",
      "About to scrape page 88\n",
      "About to scrape page 89\n",
      "About to scrape page 90\n",
      "About to scrape page 91\n",
      "About to scrape page 92\n",
      "About to scrape page 93\n",
      "About to scrape page 94\n",
      "About to scrape page 95\n",
      "About to scrape page 96\n",
      "About to scrape page 1\n",
      "About to scrape page 2\n",
      "About to scrape page 3\n",
      "About to scrape page 4\n",
      "About to scrape page 5\n",
      "About to scrape page 6\n",
      "About to scrape page 7\n",
      "About to scrape page 8\n",
      "About to scrape page 9\n",
      "About to scrape page 10\n",
      "About to scrape page 11\n",
      "About to scrape page 12\n",
      "About to scrape page 13\n",
      "About to scrape page 14\n",
      "About to scrape page 15\n",
      "About to scrape page 16\n",
      "About to scrape page 17\n",
      "About to scrape page 18\n",
      "About to scrape page 19\n",
      "About to scrape page 20\n",
      "About to scrape page 21\n",
      "About to scrape page 22\n",
      "About to scrape page 23\n",
      "About to scrape page 24\n",
      "About to scrape page 25\n",
      "About to scrape page 26\n",
      "About to scrape page 27\n",
      "About to scrape page 28\n",
      "About to scrape page 29\n",
      "About to scrape page 30\n",
      "About to scrape page 31\n",
      "About to scrape page 32\n",
      "About to scrape page 33\n",
      "About to scrape page 34\n",
      "About to scrape page 35\n",
      "About to scrape page 36\n",
      "About to scrape page 37\n",
      "About to scrape page 38\n",
      "About to scrape page 39\n",
      "About to scrape page 40\n",
      "About to scrape page 41\n",
      "About to scrape page 42\n",
      "About to scrape page 43\n",
      "About to scrape page 44\n",
      "About to scrape page 45\n",
      "About to scrape page 46\n",
      "About to scrape page 47\n",
      "About to scrape page 48\n",
      "About to scrape page 49\n",
      "About to scrape page 50\n",
      "About to scrape page 51\n",
      "About to scrape page 52\n",
      "About to scrape page 53\n",
      "About to scrape page 54\n",
      "About to scrape page 55\n",
      "About to scrape page 56\n",
      "About to scrape page 57\n",
      "About to scrape page 58\n",
      "About to scrape page 59\n",
      "About to scrape page 60\n",
      "About to scrape page 61\n",
      "About to scrape page 62\n",
      "About to scrape page 63\n",
      "About to scrape page 64\n",
      "About to scrape page 65\n",
      "About to scrape page 66\n",
      "About to scrape page 67\n",
      "About to scrape page 68\n",
      "About to scrape page 69\n",
      "About to scrape page 70\n",
      "About to scrape page 71\n",
      "About to scrape page 72\n",
      "About to scrape page 73\n",
      "About to scrape page 74\n",
      "About to scrape page 75\n",
      "About to scrape page 76\n",
      "About to scrape page 77\n",
      "About to scrape page 78\n",
      "About to scrape page 79\n",
      "About to scrape page 80\n",
      "About to scrape page 81\n",
      "About to scrape page 82\n",
      "About to scrape page 83\n",
      "About to scrape page 84\n",
      "About to scrape page 85\n",
      "About to scrape page 86\n",
      "About to scrape page 87\n",
      "About to scrape page 88\n",
      "About to scrape page 89\n",
      "About to scrape page 90\n",
      "About to scrape page 91\n",
      "About to scrape page 92\n",
      "About to scrape page 93\n",
      "About to scrape page 94\n",
      "About to scrape page 95\n",
      "About to scrape page 96\n",
      "About to scrape page 1\n",
      "About to scrape page 2\n",
      "About to scrape page 3\n",
      "About to scrape page 4\n",
      "About to scrape page 5\n",
      "About to scrape page 6\n",
      "About to scrape page 7\n",
      "About to scrape page 8\n",
      "About to scrape page 9\n",
      "About to scrape page 10\n",
      "About to scrape page 11\n",
      "About to scrape page 12\n",
      "About to scrape page 13\n",
      "About to scrape page 14\n",
      "About to scrape page 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to scrape page 16\n",
      "About to scrape page 17\n",
      "About to scrape page 18\n",
      "About to scrape page 19\n",
      "About to scrape page 20\n",
      "About to scrape page 21\n",
      "About to scrape page 22\n",
      "About to scrape page 23\n",
      "About to scrape page 24\n",
      "About to scrape page 25\n",
      "About to scrape page 26\n",
      "About to scrape page 27\n",
      "About to scrape page 28\n",
      "About to scrape page 29\n",
      "About to scrape page 30\n",
      "About to scrape page 31\n",
      "About to scrape page 32\n",
      "About to scrape page 33\n",
      "About to scrape page 34\n",
      "About to scrape page 35\n",
      "About to scrape page 36\n",
      "About to scrape page 37\n",
      "About to scrape page 38\n",
      "About to scrape page 39\n",
      "About to scrape page 40\n",
      "About to scrape page 41\n",
      "About to scrape page 42\n",
      "About to scrape page 43\n",
      "About to scrape page 44\n",
      "About to scrape page 45\n",
      "About to scrape page 46\n",
      "About to scrape page 47\n",
      "About to scrape page 48\n",
      "About to scrape page 49\n",
      "About to scrape page 50\n",
      "About to scrape page 51\n",
      "About to scrape page 52\n",
      "About to scrape page 53\n",
      "About to scrape page 54\n",
      "About to scrape page 55\n",
      "About to scrape page 56\n",
      "About to scrape page 57\n",
      "About to scrape page 58\n",
      "About to scrape page 59\n",
      "About to scrape page 60\n",
      "About to scrape page 61\n",
      "About to scrape page 62\n",
      "About to scrape page 63\n",
      "About to scrape page 64\n",
      "About to scrape page 65\n",
      "About to scrape page 66\n",
      "About to scrape page 67\n",
      "About to scrape page 68\n",
      "About to scrape page 69\n",
      "About to scrape page 70\n",
      "About to scrape page 71\n",
      "About to scrape page 72\n",
      "About to scrape page 73\n",
      "About to scrape page 74\n",
      "About to scrape page 75\n",
      "About to scrape page 76\n",
      "About to scrape page 77\n",
      "About to scrape page 78\n",
      "About to scrape page 79\n",
      "About to scrape page 80\n",
      "About to scrape page 81\n",
      "About to scrape page 82\n",
      "About to scrape page 83\n",
      "About to scrape page 84\n",
      "About to scrape page 85\n",
      "About to scrape page 86\n",
      "About to scrape page 87\n",
      "About to scrape page 88\n",
      "About to scrape page 89\n",
      "About to scrape page 90\n",
      "About to scrape page 91\n",
      "About to scrape page 92\n",
      "About to scrape page 93\n",
      "About to scrape page 94\n",
      "About to scrape page 95\n",
      "About to scrape page 96\n",
      "About to scrape page 1\n",
      "About to scrape page 2\n",
      "About to scrape page 3\n",
      "About to scrape page 4\n",
      "About to scrape page 5\n",
      "About to scrape page 6\n",
      "About to scrape page 7\n",
      "About to scrape page 8\n",
      "About to scrape page 9\n",
      "About to scrape page 10\n",
      "About to scrape page 11\n",
      "About to scrape page 12\n",
      "About to scrape page 13\n",
      "About to scrape page 14\n",
      "About to scrape page 15\n",
      "About to scrape page 16\n",
      "About to scrape page 17\n",
      "About to scrape page 18\n",
      "About to scrape page 19\n",
      "About to scrape page 20\n",
      "About to scrape page 21\n",
      "About to scrape page 22\n",
      "About to scrape page 23\n",
      "About to scrape page 24\n",
      "About to scrape page 25\n",
      "About to scrape page 26\n",
      "About to scrape page 27\n",
      "About to scrape page 28\n",
      "About to scrape page 29\n",
      "About to scrape page 30\n",
      "About to scrape page 31\n",
      "About to scrape page 32\n",
      "About to scrape page 33\n",
      "About to scrape page 34\n",
      "About to scrape page 35\n",
      "About to scrape page 36\n",
      "About to scrape page 37\n",
      "About to scrape page 38\n",
      "About to scrape page 39\n",
      "About to scrape page 40\n",
      "About to scrape page 41\n",
      "About to scrape page 42\n",
      "About to scrape page 43\n",
      "About to scrape page 44\n",
      "About to scrape page 45\n",
      "About to scrape page 46\n",
      "About to scrape page 47\n",
      "About to scrape page 48\n",
      "About to scrape page 49\n",
      "About to scrape page 50\n",
      "About to scrape page 51\n",
      "About to scrape page 52\n",
      "About to scrape page 53\n",
      "About to scrape page 54\n",
      "About to scrape page 55\n",
      "About to scrape page 56\n",
      "About to scrape page 57\n",
      "About to scrape page 58\n",
      "About to scrape page 59\n",
      "About to scrape page 60\n",
      "About to scrape page 61\n",
      "About to scrape page 62\n",
      "About to scrape page 63\n",
      "About to scrape page 64\n",
      "About to scrape page 65\n",
      "About to scrape page 66\n",
      "About to scrape page 67\n",
      "About to scrape page 68\n",
      "About to scrape page 69\n",
      "About to scrape page 70\n",
      "About to scrape page 71\n",
      "About to scrape page 72\n",
      "About to scrape page 73\n",
      "About to scrape page 74\n",
      "About to scrape page 75\n",
      "About to scrape page 76\n",
      "About to scrape page 77\n",
      "About to scrape page 78\n",
      "About to scrape page 79\n",
      "About to scrape page 80\n",
      "About to scrape page 81\n",
      "About to scrape page 82\n",
      "About to scrape page 83\n",
      "About to scrape page 84\n",
      "About to scrape page 85\n",
      "About to scrape page 86\n",
      "About to scrape page 87\n",
      "About to scrape page 88\n",
      "About to scrape page 89\n",
      "About to scrape page 90\n",
      "About to scrape page 91\n",
      "About to scrape page 92\n",
      "About to scrape page 93\n",
      "About to scrape page 94\n",
      "About to scrape page 95\n",
      "About to scrape page 96\n",
      "About to scrape page 1\n",
      "About to scrape page 2\n",
      "About to scrape page 3\n",
      "About to scrape page 4\n",
      "About to scrape page 5\n",
      "About to scrape page 6\n",
      "About to scrape page 7\n",
      "About to scrape page 8\n",
      "About to scrape page 9\n",
      "About to scrape page 10\n",
      "About to scrape page 11\n",
      "About to scrape page 12\n",
      "About to scrape page 13\n",
      "About to scrape page 14\n",
      "About to scrape page 15\n",
      "About to scrape page 16\n",
      "About to scrape page 17\n",
      "About to scrape page 18\n",
      "About to scrape page 19\n",
      "About to scrape page 20\n",
      "About to scrape page 21\n",
      "About to scrape page 22\n",
      "About to scrape page 23\n",
      "About to scrape page 24\n",
      "About to scrape page 25\n",
      "About to scrape page 26\n",
      "About to scrape page 27\n",
      "About to scrape page 28\n",
      "About to scrape page 29\n",
      "About to scrape page 30\n",
      "About to scrape page 31\n",
      "About to scrape page 32\n",
      "About to scrape page 33\n",
      "About to scrape page 34\n",
      "About to scrape page 35\n",
      "About to scrape page 36\n",
      "About to scrape page 37\n",
      "About to scrape page 38\n",
      "About to scrape page 39\n",
      "About to scrape page 40\n",
      "About to scrape page 41\n",
      "About to scrape page 42\n",
      "About to scrape page 43\n",
      "About to scrape page 44\n",
      "About to scrape page 45\n",
      "About to scrape page 46\n",
      "About to scrape page 47\n",
      "About to scrape page 48\n",
      "About to scrape page 49\n",
      "About to scrape page 50\n",
      "About to scrape page 51\n",
      "About to scrape page 52\n",
      "About to scrape page 53\n",
      "About to scrape page 54\n",
      "About to scrape page 55\n",
      "About to scrape page 56\n",
      "About to scrape page 57\n",
      "About to scrape page 58\n",
      "About to scrape page 59\n",
      "About to scrape page 60\n",
      "About to scrape page 61\n",
      "About to scrape page 62\n",
      "About to scrape page 63\n",
      "About to scrape page 64\n",
      "About to scrape page 65\n",
      "About to scrape page 66\n",
      "About to scrape page 67\n",
      "About to scrape page 68\n",
      "About to scrape page 69\n",
      "About to scrape page 70\n",
      "About to scrape page 71\n",
      "About to scrape page 72\n",
      "About to scrape page 73\n",
      "About to scrape page 74\n",
      "About to scrape page 75\n",
      "About to scrape page 76\n",
      "About to scrape page 77\n",
      "About to scrape page 78\n",
      "About to scrape page 79\n",
      "About to scrape page 80\n",
      "About to scrape page 81\n",
      "About to scrape page 82\n",
      "About to scrape page 83\n",
      "About to scrape page 84\n",
      "About to scrape page 85\n",
      "About to scrape page 86\n",
      "About to scrape page 87\n",
      "About to scrape page 88\n",
      "About to scrape page 89\n",
      "About to scrape page 90\n",
      "About to scrape page 91\n",
      "About to scrape page 92\n",
      "About to scrape page 93\n",
      "About to scrape page 94\n",
      "About to scrape page 95\n",
      "About to scrape page 96\n",
      "About to scrape page 1\n",
      "About to scrape page 2\n",
      "About to scrape page 3\n",
      "About to scrape page 4\n",
      "About to scrape page 5\n",
      "About to scrape page 6\n",
      "About to scrape page 7\n",
      "About to scrape page 8\n",
      "About to scrape page 9\n",
      "About to scrape page 10\n",
      "About to scrape page 11\n",
      "About to scrape page 12\n",
      "About to scrape page 13\n",
      "About to scrape page 14\n",
      "About to scrape page 15\n",
      "About to scrape page 16\n",
      "About to scrape page 17\n",
      "About to scrape page 18\n",
      "About to scrape page 19\n",
      "About to scrape page 20\n",
      "About to scrape page 21\n",
      "About to scrape page 22\n",
      "About to scrape page 23\n",
      "About to scrape page 24\n",
      "About to scrape page 25\n",
      "About to scrape page 26\n",
      "About to scrape page 27\n",
      "About to scrape page 28\n",
      "About to scrape page 29\n",
      "About to scrape page 30\n",
      "About to scrape page 31\n",
      "About to scrape page 32\n",
      "About to scrape page 33\n",
      "About to scrape page 34\n",
      "About to scrape page 35\n",
      "About to scrape page 36\n",
      "About to scrape page 37\n",
      "About to scrape page 38\n",
      "About to scrape page 39\n",
      "About to scrape page 40\n",
      "About to scrape page 41\n",
      "About to scrape page 42\n",
      "About to scrape page 43\n",
      "About to scrape page 44\n",
      "About to scrape page 45\n",
      "About to scrape page 46\n",
      "About to scrape page 47\n",
      "About to scrape page 48\n",
      "About to scrape page 49\n",
      "About to scrape page 50\n",
      "About to scrape page 51\n",
      "About to scrape page 52\n",
      "About to scrape page 53\n",
      "About to scrape page 54\n",
      "About to scrape page 55\n",
      "About to scrape page 56\n",
      "About to scrape page 57\n",
      "About to scrape page 58\n",
      "About to scrape page 59\n",
      "About to scrape page 60\n",
      "About to scrape page 61\n",
      "About to scrape page 62\n",
      "About to scrape page 63\n",
      "About to scrape page 64\n",
      "About to scrape page 65\n",
      "About to scrape page 66\n",
      "About to scrape page 67\n",
      "About to scrape page 68\n",
      "About to scrape page 69\n",
      "About to scrape page 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to scrape page 71\n",
      "About to scrape page 72\n",
      "About to scrape page 73\n",
      "About to scrape page 74\n",
      "About to scrape page 75\n",
      "About to scrape page 76\n",
      "About to scrape page 77\n",
      "About to scrape page 78\n",
      "About to scrape page 79\n",
      "About to scrape page 80\n",
      "About to scrape page 81\n",
      "About to scrape page 82\n",
      "About to scrape page 83\n",
      "About to scrape page 84\n",
      "About to scrape page 85\n",
      "About to scrape page 86\n",
      "About to scrape page 87\n",
      "About to scrape page 88\n",
      "About to scrape page 89\n",
      "About to scrape page 90\n",
      "About to scrape page 91\n",
      "About to scrape page 92\n",
      "About to scrape page 93\n",
      "About to scrape page 94\n",
      "About to scrape page 95\n",
      "About to scrape page 96\n",
      "About to scrape page 1\n",
      "About to scrape page 2\n",
      "About to scrape page 3\n",
      "About to scrape page 4\n",
      "About to scrape page 5\n",
      "About to scrape page 6\n",
      "About to scrape page 7\n",
      "About to scrape page 8\n",
      "About to scrape page 9\n",
      "About to scrape page 10\n",
      "About to scrape page 11\n",
      "About to scrape page 12\n",
      "About to scrape page 13\n",
      "About to scrape page 14\n",
      "About to scrape page 15\n",
      "About to scrape page 16\n",
      "About to scrape page 17\n",
      "About to scrape page 18\n",
      "About to scrape page 19\n",
      "About to scrape page 20\n",
      "About to scrape page 21\n",
      "About to scrape page 22\n",
      "About to scrape page 23\n",
      "About to scrape page 24\n",
      "About to scrape page 25\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-b9ad3f400f9c>\u001b[0m in \u001b[0;36mone_page_scrape\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_product_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprod_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-40025bfd6c84>\u001b[0m in \u001b[0;36mget_product_html\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"That's not you, right?\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Captcha\\'d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Captcha'd",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-5f668a60d8c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprices_32_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomponents_32_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_urls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster_prices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-35a6f18bded4>\u001b[0m in \u001b[0;36mscrape_all\u001b[0;34m(url_list, master_prices, master_components, start_at)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Scrapes all pages in url_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_at\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mproducts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_page_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmaster_prices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster_prices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-b9ad3f400f9c>\u001b[0m in \u001b[0;36mone_page_scrape\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_product_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprod_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mcurrent_page_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'component_html'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mproducts_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproducts_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_page_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "prices_32_to, components_32_to = scrape_all(master_urls, master_prices, master_components, start_at=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\\n<head>\\n<title>Are you a human?</title>\\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=EDGE\" /><meta charset=\"UTF-8\" />\\n<link rel=\"shortcut icon\" type=\"image/x-icon\" href=\"//c1.neweggimages.com/WebResource/Themes/2005/Nest/Newegg.ico\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://fonts.googleapis.com/css?family=Open+Sans:400,300,300italic,400italic,700,700italic|Open+Sans+Condensed:300,300italic,700\">\\n<style type=\"text/css\">\\np{font-size:16px;color:#4d4d4d;padding:0;margin:0 0 5px}a img,a:hover img,a:visited img{border:0}.button-primary,.button-primary:focus,.button-primary:link,.button-primary:visited{font-family:\\'Open Sans Condensed\\',\\'Arial Narrow\\',\\'Helvetica Narrow\\',arial,helvetica,sans-serif;letter-spacing:1px;font-size:14px;font-weight:700;font-stretch:condensed;text-align:center;text-decoration:none;cursor:pointer;border-radius:4px;border:2px solid #E68626;display:inline-block;padding:9px 15px;margin:15px 0 0;outline:0;color:#552F00;background-color:#FFC010;background:linear-gradient(to bottom,#FFC010,#F9A21B);text-transform:uppercase}h1,h2{padding:0}.button-primary:active,.button-primary:hover{color:#552F00;background-color:#F9A21B;background:linear-gradient(to bottom,#F9A21B,#FFC010);border-color:#E68626}h1{margin:0;font-size:100px;line-height:120px;font-weight:700;color:#33425a}h2{color:#cc4e00;font-size:29px;margin:10px 0 20px}\\n</style>\\n<script type=\"text/javascript\" src=\"//c1.neweggimages.com/WebResource/Scripts/USA/TP_jQueryPlugin/jquery-1.10.2.min.js?purge=1\"></script>\\n<script src=\"https://www.google.com/recaptcha/api.js\"  type=\"text/javascript\" ></script>\\n<script type=\"text/javascript\">\\nvar win = jQuery(this);\\nif (win.width() < 900) {\\n    window.resizeTo(900, win.height());\\n}\\nvar why = \\'0\\';\\nfunction getReferer() {\\n    var reg = new RegExp(\"(^|&)referer=([^&]*)(&|$)\");\\n    var r = window.location.search.substr(1).match(reg);\\n    var referer = window.location.origin;\\n    if (r) {\\n        referer = unescape(r[2]);\\n    }\\n    if (referer.indexOf(\\'?\\') > 0) {\\n        referer += \\'&\\';\\n    } else {\\n        referer += \\'?\\';\\n    }\\n    referer += \\'recaptcha=pass\\';\\n\\n    return referer;\\n}\\nvar postEventData = function (refer) {\\n    var items = location.hostname.split(\\'.\\');\\n    items.shift();\\n    var topDomain = items.join(\\'.\\');\\n    var reg = /^https?\\\\:\\\\/\\\\/\\\\w+\\\\.([^\\\\/\\\\s]+)/;\\n    var match = refer.match(reg);\\n    if(match){\\n        if(match[1] !== topDomain) {\\n            refer = location.origin;\\n        }\\n    }\\n    else {\\n        refer = location.origin+\\'/\\'+refer.replace(/^\\\\//,\\'\\');\\n    }\\n    jQuery.ajax({\\n        type: \"POST\",\\n        url: \"https://pf.newegg.com/r3\",\\n        data: JSON.stringify({c: document.cookie }),\\n        dataType: \"json\",\\n        contentType: \"application/json\",\\n        timeout:2000,\\n        success: function () {\\n            window.location.href = refer;\\n        }\\n    }).fail(function () {\\n        window.location.href = refer;\\n    });\\n};\\nvar reCAPTCHACallBack = function () {\\n    var rResponse = jQuery(\"#g-recaptcha-response\").val();\\n    if (rResponse) {\\n        jQuery.post(window.location.href, { t: rResponse, cookieEnabled: !!navigator.cookieEnabled, why: why }, function (data, status) {\\n            if (data === \\'success\\') {\\n                var refer = getReferer();\\n                postEventData(refer);\\n                var noprotocl = refer.replace(\"http://\", \"\").replace(\"https://\", \"\");\\n                var questionMarkLocation = noprotocl.indexOf(\"?\");\\n                var label = questionMarkLocation > 0 ? noprotocl.slice(0, questionMarkLocation) : noprotocl;\\n                ga(\\'send\\', \\'event\\', \\'Captcha\\', \\'Click\\', label);\\n                \\n            } else {\\n                window.location.href = window.location.href + \\'&retry=1\\';\\n            }\\n        });\\n    }\\n};\\n(function (i, s, o, g, r, a, m) {\\n    i[\\'GoogleAnalyticsObject\\'] = r; i[r] = i[r] || function () {\\n        (i[r].q = i[r].q || []).push(arguments)\\n    }, i[r].l = 1 * new Date(); a = s.createElement(o),\\n    m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)\\n})(window, document, \\'script\\', \\'https://www.google-analytics.com/analytics.js\\', \\'ga\\');\\nga(\\'create\\', \\'UA-1147542-13\\', \\'auto\\');\\nga(\\'send\\', \\'pageview\\');\\n</script>\\n</head>\\n<body style=\"font-family: \\'Open Sans\\', Helvetica, Arial, sans-serif; line-height: 1.36;\">\\n<div style=\"width: 760px;overflow: hidden;margin:120px auto;\">\\n    <div style=\"float: left;padding: 40px 20px 40px 40px;\">\\n    <a style=\"border: none;\" href=\"https://www.newegg.com/\">\\n        <img alt=\"Newegg- Computer Parts, Laptops, Electronics, HDTVs, Digital Cameras and More!\" width=\"216\" height=\"102\" src=\"//images10.newegg.com/WebResource/Themes/2005/Nest/neLogoUS.1.png\" />\\n    </a>\\n    </div>\\n    <div style=\"float: right;border-left: 1px solid #ccc; padding: 40px 40px 70px 40px;\">\\n<script type=\"text/javascript\">\\nvar cookiesEnable=\"cookie\"in document&&(document.cookie.length>0||(document.cookie=\"test\").indexOf.call(document.cookie,\"test\")>-1);cookiesEnable||document.write(\"<p>Please enable cookie to continue.</p>\");\\n</script>\\n    <h1>Robot?</h1><h2>That\\'s not you, right?</h2><p>Of course you\\'re not, just assure us below.</p>\\n    <p>If you have any questions, please give us a <a title=\"Feedback\" onclick=\"javascript:newegg_inhouse_feedback && newegg_inhouse_feedback.show();\" id=\"newegg_footer_feedback\" style=\"cursor: pointer;text-decoration: underline;\">Feedback</a>.</p>\\n    <div class=\"g-recaptcha-container\">\\n            <div id=\"g-recaptcha\" class=\"g-recaptcha\" data-sitekey=\"6Ld0av8SAAAAAA_bWcLCPqT109QEfdRp0w50GCsq\" data-callback=\"reCAPTCHACallBack\"></div>\\n    </div>\\n</div>\\n<script type=\"text/javascript\">\\nvar _na = _na || [];\\n(function() {\\n  var na = document.createElement(\\'script\\'); na.type = \\'text/javascript\\'; na.async = true;\\n  na.src = \\'https://pf.newegg.com/na.js\\';\\n  var s = document.getElementsByTagName(\\'script\\')[0]; s.parentNode.insertBefore(na, s);\\n})();\\nvar newegg_inhouse_feedback=null,newegg_inhouse_search_feedback=null;function global_newegg_feedback_system(){null==newegg_inhouse_feedback&&(newegg_inhouse_feedback=new neweggFeedback.NeweggSurvey({}))}!function(){var e=document.location.protocol;if(\"http:\"==e||\"https:\"==e){var n=document.createElement(\"script\");n.type=\"text/javascript\",n.async=!0,n.src=\"//promotions.newegg.com/Newegg/Survey/newegg-feedback.min.js\";var g=document.getElementsByTagName(\"head\")[0].childNodes[0];g.parentNode.insertBefore(n,g),n.onload=function(){global_newegg_feedback_system()}}}();\\nvar Web={StateManager:{Cookies:{get:function(e){for(var t=document.cookie.split(\";\"),n=0;n<t.length;n++){var o=t[n].split(\"=\");if(e==decodeURIComponent(o[0].trim()))return unescape(o[1])}return null},Name:{UTMA:\"__utma\",NVTC:\"NVTC\",NID:\"NV_NID\",SPT:\"NV_SPT\"}}}};\\n</script>\\n</div>\\n</body>\\n</html>\\n'"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.newegg.com/Product/ProductList.aspx?Submit=Property&N=100019096%2050010772%2050001186%2050010418%208000&IsNodeId=1&page=1&bop=And&PageSize=96&order=RELEASE&recaptcha=pass&recaptcha=pass'\n",
    "r = requests.get(url)\n",
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's not you, right?\""
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h2').contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_11_to = pd.read_csv('master_component_html.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_11_to = pd.read_csv('master_price_html.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>component_html</th>\n",
       "      <th>price_html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE HTML&gt;\\r\\n&lt;html lang=\"en\"&gt;\\r\\n&lt;head&gt;\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE HTML&gt;\\r\\n&lt;html lang=\"en\"&gt;\\r\\n&lt;head&gt;\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE HTML&gt;\\r\\n&lt;html lang=\"en\"&gt;\\r\\n&lt;head&gt;\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  component_html  \\\n",
       "0           0             NaN   \n",
       "1           0             NaN   \n",
       "2           0             NaN   \n",
       "\n",
       "                                          price_html  \n",
       "0  <!DOCTYPE HTML>\\r\\n<html lang=\"en\">\\r\\n<head>\\...  \n",
       "1  <!DOCTYPE HTML>\\r\\n<html lang=\"en\">\\r\\n<head>\\...  \n",
       "2  <!DOCTYPE HTML>\\r\\n<html lang=\"en\">\\r\\n<head>\\...  "
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_11_to.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = prices_11_to.iloc[2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_11_to.to_csv('11_to_14_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_11_to.to_csv('11_to_14_components.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_11_to.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.to_csv('first_5_prices_backup.csv')\n",
    "components.to_csv('first_5_components_backup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prices_2 = pd.read_csv('master_component_html.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prices_2.to_csv('6_to_11_component.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prices = pd.read_csv('prices.csv')\n",
    "test_components = pd.read_csv('components.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11_to_14_components.csv             prices.csv\r\n",
      "11_to_14_prices.csv                 scale-scrape.ipynb\r\n",
      "6_to_11_component.csv               scrape-amazon.ipynb\r\n",
      "6_to_11_price.csv                   scrape-newegg.ipynb\r\n",
      "README.md                           scrape-nutrition.ipynb\r\n",
      "components.csv                      scrape-stocks.ipynb\r\n",
      "first_5_components_backup.csv       test_components.csv\r\n",
      "first_5_prices_backup.csv           test_components.html\r\n",
      "master_component_html.csv           test_prices.csv\r\n",
      "master_price_html.csv               tibbott-project-luther-proposal.pdf\r\n",
      "newegg-utils.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_5_p = pd.read_csv('first_5_prices_backup.csv')\n",
    "first_5_c = pd.read_csv('first_5_components_backup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "six_to_eleven_p = pd.read_csv('6_to_11_price.csv')\n",
    "six_to_eleven_c = pd.read_csv('6_to_11_component.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "eleven_to_fourteen_p = pd.read_csv('11_to_14_prices.csv')\n",
    "eleven_to_fourteen_c = pd.read_csv('11_to_14_components.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_5_p.drop(labels=['Unnamed: 0', 'price_html'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_5_c.drop(labels=['Unnamed: 0', 'component_html'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-535-ec1b5810e480>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-535-ec1b5810e480>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    first_5_p.apply(func=(lambda x : x = get_components(x)))\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "first_5_p.apply(func=lambda x : get_components(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Brand', 'Lenovo'),\n",
       "             ('Series', 'IdeaCentre'),\n",
       "             ('Model', '720-18ICB (90HT0005US)'),\n",
       "             ('Part Number', '90HT0005US'),\n",
       "             ('Type', 'Gaming & Entertainment'),\n",
       "             ('Form Factor', 'Tower'),\n",
       "             ('Usage', 'Consumer'),\n",
       "             ('Colors', 'Black'),\n",
       "             ('Processor', 'Intel Core i7-8700 3.20 GHz'),\n",
       "             ('Processor Main Features', '64 bit 6-Core Processor'),\n",
       "             ('Cache Per Processor', '12 MB L3 Cache'),\n",
       "             ('Memory', '16 GB DDR4 2666 + 16 GB Optane Memory'),\n",
       "             ('Storage', '2 TB 7200 RPM HDD'),\n",
       "             ('Optical Drive', 'DVDRW'),\n",
       "             ('Graphics', 'NVIDIA GeForce GTX 1050 Ti 4 GB GDDR5'),\n",
       "             ('Power Supply', '400W'),\n",
       "             ('Operating System', 'Windows 10 Home 64-Bit'),\n",
       "             ('CPU Type', 'Intel Core i7 8th Gen'),\n",
       "             ('CPU Speed', '8700 (3.20 GHz)'),\n",
       "             ('L3 Cache Per CPU', '12 MB'),\n",
       "             ('CPU Main Features', '64 bit 6-Core Processor'),\n",
       "             ('GPU/VGA Type', 'NVIDIA GeForce GTX 1050 Ti'),\n",
       "             ('Video Memory', '4 GB GDDR5'),\n",
       "             ('Virtual Reality Ready', 'Yes'),\n",
       "             ('Memory Capacity', '16 GB DDR4'),\n",
       "             ('Memory Speed', 'DDR4 2666'),\n",
       "             ('Memory Spec', '8 GB x 2'),\n",
       "             ('Memory Slot (Total)', '2'),\n",
       "             ('Maximum Memory Supported', '32 GB'),\n",
       "             ('Optane Memory', '16 GB'),\n",
       "             ('HDD', '2 TB'),\n",
       "             ('HDD RPM', '7200rpm'),\n",
       "             ('Optical Drive Type', 'DVDRW'),\n",
       "             ('Screen Size', 'No Screen'),\n",
       "             ('LAN Speed', '10/100/1000Mbps'),\n",
       "             ('WLAN', '802.11ac Wireless LAN'),\n",
       "             ('Bluetooth', 'Bluetooth 4.1'),\n",
       "             ('Mouse Type', 'Wired Mouse'),\n",
       "             ('Keyboard Type', 'Wired Keyboard'),\n",
       "             ('Dimensions (H x W x D)', '12.78\" x 6.50\" x 14.80\"'),\n",
       "             ('Weight', '19.84 lbs.')])"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_components(first_5_p.iloc[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'df3_final.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-90c6d614e8d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df3_final.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'df3_final.csv' does not exist"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv('df3_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
